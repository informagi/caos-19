{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as Et\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from pprint import pprint\n",
    "import subprocess\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import ndcg_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyserini.search import pysearch\n",
    "from pyserini.search import pyquerybuilder\n",
    "from pyserini.index import pyutils\n",
    "from pyserini.analysis import pyanalysis\n",
    "from pyserini.pyclass import autoclass\n",
    "from pyserini.analysis.pyanalysis import get_lucene_analyzer\n",
    "\n",
    "#Mirrors of old indices are archived here\n",
    "#https://github.com/castorini/anserini/blob/master/docs/experiments-cord19.md\n",
    "index_loc = '/home/tmschoegje/Desktop/caos-19/lucene-index-cord19-paragraph-2020-05-19/'\n",
    "searcher = pysearch.SimpleSearcher(index_loc)\n",
    "index_utils = pyutils.IndexReaderUtils(index_loc)\n",
    "\n",
    "#Additionally, you need the metadata.csv of the corresponding index, which is included in the CORD-19 releases\n",
    "#https://ai2-semanticscholar-cord-19.s3-us-west-2.amazonaws.com/historical_releases.html\n",
    "metadatafile = \"/home/tmschoegje/Desktop/caos-19/metadata.csv\"\n",
    "\n",
    "\n",
    "docidfile = '/home/tmschoegje/Desktop/caos-19/trecdata/docids-rnd2.txt'\n",
    "topicsfile = \"/home/tmschoegje/Desktop/caos-19/trecdata/topics-rnd2.xml\"\n",
    "qrelname = \"/home/tmschoegje/Desktop/caos-19/trecdata/qrels-rnd2.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#manual topic classification into tasks\n",
    "rnd3classes = [2, 0, 3, 0, 3, 7, 7, 7, 6, 5, 4, 5, 0, 0, 0, 0, 4, 5, 5, 1, 0, 1, 1, 1, 1, 7, 7, 3, 3, 3, 2, 2, 3, 3, 9, 2, 2, 3, 3, 2]\n",
    "rnd3confidence = [1, 1, 1, 0.5, 0.5, 1, 1, 0.5, 0.5, 1, 0, 0.5, 1, 0, 1, 1, 0.75, 0.25, 0.25, 0.5, 0.5, 0.75, 0.75, 0.75, 0.75, 1, 0.5, 1, 1, 1, 0, 1, 1, 0, 0, 0.5, 1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Used to read in metadata for the docids this round\n",
    "def prepTREC(fname):\n",
    "    #get valid TREC ids for this round\n",
    "    TRECids = []\n",
    "    f = open(fname)\n",
    "    for line in f.readlines():\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        TRECids.append(line)\n",
    "    f.close()\n",
    "    \n",
    "    metadata = pd.read_csv(metadatafile)\n",
    "    #now we filter all TREC ids we don't need\n",
    "    metadata = metadata[metadata.cord_uid.isin(TRECids)]\n",
    "    metadata.drop_duplicates(subset='cord_uid', keep='first', inplace=True)\n",
    "    \n",
    "    return metadata\n",
    "\n",
    "#Used to read journal priors from the doc\n",
    "def prepJournals(fname):\n",
    "    f = open(fname)\n",
    "    journals = dict()\n",
    "    for line in f.readlines():\n",
    "        if line[-1] == '\\n':\n",
    "            line = line[:-1]\n",
    "        ls = line.split(\" \")\n",
    "        journals[ls[1]] = ls[0]\n",
    "    f.close()\n",
    "\n",
    "    return journals\n",
    "\n",
    "#Used to get a specific journal's prior value\n",
    "#cord_uid is id of document, metadata contains metadata.csv, \n",
    "#journals is a list of journals from journalpriors.txt (see prepJournals)\n",
    "def getJPrior(cord_uid, metadata, journals):\n",
    "    #Get journal for this item\n",
    "    journal = metadata[metadata['cord_uid'] == cord_uid]['journal']\n",
    "    if journal.to_string(index=False).strip() in journals:\n",
    "        return journals[journal.to_string(index=False).strip()]\n",
    "    else:\n",
    "        #if we have no knowledge, we assume the relevance is 0 (neutral)\n",
    "        return 0\n",
    "\n",
    "#Used to read TREC topics\n",
    "def readTopics(fname):\n",
    "    root = Et.parse(fname).getroot()\n",
    "    topics = []\n",
    "    for num, topic in enumerate(root):\n",
    "        #print(topic[0].text) #query\n",
    "        topics.append([topic[0].text, rnd3classes[num]])\n",
    "        #print(topic[1].text) #question\n",
    "        #print(topic[2].text) #narrative\n",
    "    return topics\n",
    "\n",
    "#Used to read in a run's ranking\n",
    "def readAnserini(fname):\n",
    "    res=[]\n",
    "    f = open(fname)\n",
    "    #f.readline()\n",
    "    for line in f.readlines():\n",
    "        vals = line.strip().split(\" \")\n",
    "        #topic, rank, cord_id, score\n",
    "        res.append([vals[0], vals[3], vals[2], vals[4]])\n",
    "    return res\n",
    "\n",
    "#Used to prepare results in submission format\n",
    "def writeBM25results(results, runtitle):\n",
    "    f = open(runtitle, \"w\")\n",
    "    #topic, rank, cord_id, score\n",
    "    for result in results:\n",
    "        #print(result)\n",
    "        f.write(result[0] + \" Q0 \" + result[2] + \" 1 \" + str(result[3]) + \" \" + runtitle + \"\\n\")\n",
    "    f.close()\n",
    "    \n",
    "\n",
    "#read the qrels file\n",
    "def getqrels(fname):\n",
    "    qrels = []\n",
    "    for line in open(fname).readlines():\n",
    "        vals = line.strip().split(\" \")\n",
    "        #topic, cord_uid, qrel, assessround\n",
    "        qrels.append([int(vals[0]), vals[3], float(vals[4]), float(vals[1])])\n",
    "\n",
    "    qrels = np.array(qrels, dtype=\"O\")\n",
    "    return qrels\n",
    "\n",
    "#find qrel for a cord uid\n",
    "def get_qrel(cord_uid, topic_id, qrels):\n",
    "\n",
    "    topicrels = qrels[qrels[:,0] == topic_id]\n",
    "\n",
    "    qrel_uids = [qrel[1] for qrel in topicrels]\n",
    "    #print(qrel_uids.index(cord_uid))\n",
    "    index = qrel_uids.index(cord_uid)\n",
    "    #print(qrels[index,2])\n",
    "    if(qrels[index,2] > 0):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ndcg after filtering unknown docs - sakai 2007 says this is more stable than bpref\n",
    "\n",
    "#Note: it's nicer to do NDCG over all known qrels. \n",
    "#Implementation of this was limited - so we only considered the qrels in the top 30k documents\n",
    "\n",
    "def ndcg(runname, qrelname):\n",
    "    qrels = getqrels(qrelname)\n",
    "    \n",
    "    preds = []\n",
    "    #first parse predictions\n",
    "    for line in open(runname).readlines():\n",
    "        #topic, unused, cord_uid, rank, score, runname\n",
    "        vals = line.strip().split(\" \")\n",
    "        #topic, cord_uid, score, rank\n",
    "        preds.append([int(vals[0]), vals[2], float(vals[4]), int(vals[3])])\n",
    "        \n",
    "    #print('hi')\n",
    "    #print(len(preds))\n",
    "    #print(len(qrels))\n",
    "    knownpreds = []\n",
    "    \n",
    "    for num, pred in enumerate(preds):\n",
    "        #get qrels for the given topic\n",
    "        qrels_topic = qrels[qrels[:,0] == pred[0]]\n",
    "        qrel_uids = [val[1] for val in qrels_topic]\n",
    "\n",
    "        #filter all preds not in qrels\n",
    "        if(pred[1] in qrel_uids):\n",
    "            #add known prediction with predicted score and real score\n",
    "            knownpreds.append([pred[0], pred[1], pred[2], get_qrel(pred[1], pred[0], qrels_topic), pred[3]])\n",
    "            \n",
    "    knownpreds = np.array(knownpreds, dtype=\"O\")\n",
    "    \n",
    "    #TODO update for round2+ topics\n",
    "    ndcgs = []\n",
    "    for t in range(1, 31):\n",
    "        knownpreds_t = knownpreds[knownpreds[:,0] == t]\n",
    "        \n",
    "        #cross validation on knownpreds_t\n",
    "        #If this topic has at least 5 documens with known qrels, we compute it using 5x cross validation\n",
    "        #Otherwise, we ignore the ndcg for this topic. Afterwards, average for all topics\n",
    "        \n",
    "        n_splits = 5\n",
    "        if(len(knownpreds_t) > 5):\n",
    "            kf = KFold(n_splits)\n",
    "            for train_index, test_index in kf.split(knownpreds_t):\n",
    "        \n",
    "                sortedqrel = []\n",
    "                sortedqpred = []\n",
    "                for pred_ind, pred in enumerate(knownpreds_t):\n",
    "                    if pred_ind in train_index:\n",
    "                        #get corresponding pred's qrel\n",
    "                        sortedqrel.append(pred[3])#get_qrel(pred[1], pred[0], qrels))\n",
    "                        #ground truth\n",
    "                        sortedqpred.append(pred[2])        \n",
    "            \n",
    "                if(len(sortedqrel) > 1):\n",
    "                    ndcgs.append(ndcg_score(np.asarray([sortedqrel]), np.asarray([sortedqpred]), k=10))\n",
    "                else:\n",
    "                    print('how did i get here')\n",
    "           \n",
    "        else:\n",
    "            pass           \n",
    "        \n",
    "    return np.mean(ndcgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5225502184047945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5226202172483354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5357320329022079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5268356431706291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5158641439101874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.508383664126815\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.49849152805133884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4995929562186969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4882150231210602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py:2882: DtypeWarning: Columns (13,14) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.491663131643002\n"
     ]
    }
   ],
   "source": [
    "# Rerank by journal\n",
    "def rerank(results, topics, mixer, journals):\n",
    "    metadata = prepTREC(docidfile)\n",
    "    \n",
    "    jscores = []\n",
    "    scores = []\n",
    "    for result in results:\n",
    "        jscores.append(getJPrior(result[2], metadata, journals))\n",
    "        scores.append(float(result[3]))\n",
    "    \n",
    "    for i, val in enumerate(jscores):\n",
    "        results[i][3] = mixer * float(jscores[i]) + scores[i]\n",
    "    \n",
    "    #Some ugly/quick sorting\n",
    "    def sort_key0(item):\n",
    "        return item[3]\n",
    "    def sort_key1(item):\n",
    "        return item[0]\n",
    "\n",
    "    results = sorted(results, key=sort_key0, reverse=True)\n",
    "    results = sorted(results, key=sort_key1, reverse=False)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Let's see what linear combination between the run score these two values makes sense\n",
    "for m3 in np.linspace(0, 0.5, 10):\n",
    "    \n",
    "    #This is currently the best run. Differs from the submitted runfile because it is a longer list of ranked\n",
    "    #qrels that we can use to tune with ndcg\n",
    "    #results = readAnserini('/home/tmschoegje/Desktop/caos-19/runs/testrun-best-rnd3.run')\n",
    "    \n",
    "    #Currently testing on the baseline (using query terms)\n",
    "    results = readAnserini('/home/tmschoegje/Desktop/caos-19/runs/testrun-baseline-rnd3.run')\n",
    "    \n",
    "    #print(len(results))\n",
    "    journals = prepJournals('/home/tmschoegje/Desktop/caos-19/round3/journalpriors.txt')\n",
    "    results_reranked = rerank(results, readTopics(topicsfile), m3, journals)\n",
    "    writeBM25results(results_reranked, \"/home/tmschoegje/Desktop/caos-19/runs/testrun-\" + str(m3) + '.run')\n",
    "    print(ndcg(\"/home/tmschoegje/Desktop/caos-19/runs/testrun-\" + str(m3) + '.run', qrelname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
